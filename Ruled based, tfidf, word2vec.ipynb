{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import xml.etree.ElementTree as ET\n",
    "import sys\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"3.txt\", \"r\")\n",
    "a=print(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('4.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data\n",
    "\n",
    "\n",
    "myfile = open('xyz.txt', 'w')\n",
    "myfile.writelines(data)\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"xyz.txt\", \"r\")\n",
    "a=print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code to read all the notes in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimages = [] #list of image filenames\n",
    "for root, dirs, files in os.walk(\"C:\\\\Users\\\\baner\\\\CTakes\\\\output\\\\\"):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            myimages.append(file)\n",
    "print (myimages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myimages.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "myimages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating a Dataframe consisting of all medical notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for root, dirs, files in os.walk(\"C:\\\\Users\\\\baner\\\\CTakes\\\\output\\\\\"):\n",
    "    for file in myimages:            \n",
    "        with open(os.path.join(root, file), 'r') as f:\n",
    "            text = f.read().replace('\\n', ' ')\n",
    "            new_list.append(text)\n",
    "                \n",
    "df = pd.DataFrame(new_list)\n",
    "df      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting all notes to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={ df.columns[0]: \"Note\" }, inplace = True)\n",
    "df\n",
    "df[\"Note\"] = df[\"Note\"].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'notes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing more libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "import logging\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import defaultdict\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import backend as K\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting the dataframe into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = []\n",
    "\n",
    "for d in df['Note']:\n",
    "    df_cleaned.append(d)\n",
    "df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting each note into corresponding sentences with the help of period break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(sentence):\n",
    "    result = []\n",
    "    #Split each sentence in the list, and append to result list\n",
    "    for df_cleaned in sentence:\n",
    "        result.append(df_cleaned.split(\".\"))\n",
    "    return result\n",
    "\n",
    "print(split_list(df_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_data3=split_list(df_cleaned)\n",
    "text_data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(text_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed = []\n",
    "i=0\n",
    "for i in range(0,len(text_data3)):\n",
    "    if 'smoke' in text_data3[i] or 'smoking' in text_data3[i] or 'smokes' in text_data3[i] or 'smoked' in text_data3[i] or 'cigarettes' in text_data3[i]:\n",
    "        print(text_data3[i])\n",
    "    else:\n",
    "        print('none')\n",
    "        myfile = open('ghochu.txt', 'w')\n",
    "        myfile.writelines(text_data3[i])\n",
    "        myfile.close()\n",
    "processed.append(text_data3[i])\n",
    "dates.append(re.findall( r'[0-9]+(?:\\/[0-9]+){2}', text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting sentences that are related to smoking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed=[]\n",
    "for sub_list in text_data3:\n",
    "    temp_list=[]\n",
    "    for elem in sub_list:\n",
    "        if 'smoker' in elem or 'smoking' in elem or 'smoked' in elem or 'smoke' in elem or 'smokes' in elem or 'non - smoker' in elem or 'non-smoker' in elem or 'non- smoker' in elem or 'nonsmoker' in elem or 'cigarette' in elem or 'cigarettes' in elem or 'cigs' in elem or 'cig' in elem or 'non smoker' in elem or 'past smoker' in elem or 'past-smoker' in elem or 'past- smoker' in elem or 'pastsmoker' in elem or 'past - smoker' in elem or 'tobacco' in elem or 'cigar' in elem or 'smoked' in elem or 'formersmoker' in elem or 'former-smoker' in elem or 'former smoker' in elem or 'former- smoker' in elem or 'former - smoker' in elem or 'ex- smoker' in elem or 'ex-smoker' in elem or 'ex - smoker' in elem or 'exsmoker' in elem or 'smoh' in elem or 'tob' in elem:\n",
    "            temp_list.append(elem)\n",
    "    if temp_list==[]:\n",
    "        temp_list=[None]\n",
    "    processed.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting smoking sentences to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed2=[]\n",
    "for sub_list in processed:\n",
    "    temp_list=[]\n",
    "    for elem in sub_list:\n",
    "        if len(sub_list)>1:\n",
    "            temp_list.append(','.join(sub_list))\n",
    "        elif len(sub_list)==1:\n",
    "            temp_list.append(elem)\n",
    "    processed2.append(temp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed3=[]\n",
    "for sub_list in processed2:\n",
    "    res = [] \n",
    "    for i in sub_list: \n",
    "        if i not in res: \n",
    "            res.append(i)\n",
    "    processed3.append(res)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(processed3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label']=0\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method1: Rule based system to classify smokers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(len(df)):\n",
    "    if df[0].iloc[i] is None:\n",
    "        df['Label'].iloc[i]='Not Defined' \n",
    "    elif 'pastsmoker' in df[0].iloc[i] or 'past-smoker' in df[0].iloc[i] or 'past smoker' in df[0].iloc[i] or 'formersmoker' in df[0].iloc[i] or 'former-smoker' in df[0].iloc[i] or 'former smoker' in df[0].iloc[i] or 'quit' in df[0].iloc[i] or 'past' in df[0].iloc[i] or 'stopped' in df[0].iloc[i]or 'stop' in df[0].iloc[i] or 'former' in df[0].iloc[i] or 'not smoked since' in df[0].iloc[i]  or 'past smoker' in df[0].iloc[i] or 'smoking history' in df[0].iloc[i] or 'ago' in df[0].iloc[i]:\n",
    "        df['Label'].iloc[i]='PastSmoker'\n",
    "    \n",
    "    elif 'never' in df[0].iloc[i] or 'no smoking' in df[0].iloc[i] or 'no cigar' in df[0].iloc[i] or 'no cigars' in df[0].iloc[i] or 'no cigarette' in df[0].iloc[i] or 'no cigarettes' in df[0].iloc[i] or 'no tobacco' in df[0].iloc[i] or 'not smoke' in df[0].iloc[i] or 'not smoked' in df[0].iloc[i] or 'not smoking' in df[0].iloc[i] or 'no tobacco' in df[0].iloc[i]  or 'no tob' in df[0].iloc[i]  or 'non tob' in df[0].iloc[i]  or 'non tobacco' in df[0].iloc[i] or 'not smoked' in df[0].iloc[i] or 'no pipe' in df[0].iloc[i] or 'ever' in df[0].iloc[i] or 'doesn\\'t smoke' in df[0].iloc[i] or 'nonsmoker' in df[0].iloc[i] or 'non-smoker' in df[0].iloc[i] or 'non - smoker' in df[0].iloc[i] or 'non- smoker' in df[0].iloc[i] or 'denies smoking' in df[0].iloc[i] or 'denies tobacco' in df[0].iloc[i] or 'denies cigarettes' in df[0].iloc[i] or 'denies' in df[0].iloc[i] or 'smoking: none' in df[0].iloc[i] or 'smoking: no' in df[0].iloc[i] or 'tob: none' in df[0].iloc[i]  or'tob: no' in df[0].iloc[i] or 'negative' in df[0].iloc[i] or 'nor smoke' in df[0].iloc[i] or 'nor smoked' in df[0].iloc[i] or 'nor smoking' in df[0].iloc[i] or 'no history' in df[0].iloc[i] or 'none' in df[0].iloc[i] or 'smoking ( - )' in df[0].iloc[i]:\n",
    "        df['Label'].iloc[i]='NonSmoker'\n",
    "    \n",
    "    elif 'smoker' in df[0].iloc[i] or 'smoking' in df[0].iloc[i] or 'smoke' in df[0].iloc[i]  or 'smokes' in df[0].iloc[i]  or 'occasionally' in df[0].iloc[i]   or 'tobacco' in df[0].iloc[i]:\n",
    "        df['Label'].iloc[i]='Smoker'\n",
    "    else:\n",
    "        df['Label'].iloc[i]='Not Defined'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'smoked_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### comparing the predicted labels to the actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"C:\\\\Users\\\\baner\\\\CTakes\\\\testing-RiskFactors-Gold\\\\labels_actual.csv\",index_col=None)\n",
    "df3=pd.concat([df, df2], axis=1)\n",
    "df3=df3[['Label','Label_actual']]\n",
    "df3=df3.rename(columns={\"Label\": \"Label_predicted\"})\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 )F1-SCORE For rule based system on the extracted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "df3['Label_actual_numeric'] = lb_make.fit_transform(df3['Label_actual'])\n",
    "df3['Label_predicted_numeric'] = lb_make.fit_transform(df3['Label_predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(df3['Label_actual_numeric'], df3['Label_predicted_numeric'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. ML Approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.concat([df, df2], axis=1)\n",
    "df3=df3[[0,'Label_actual']]\n",
    "df3=df3.rename(columns={0: \"Text\"})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for i in range(len(df3)):\n",
    "    if df3['Text'].iloc[i] is None:\n",
    "        df3['Text'].iloc[i]='None' \n",
    "    \n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df3['Text'], df3['Label_actual'], \\\n",
    "                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "print('Load %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))\n",
    "print('Show a review in the training set : \\n', X_train.iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatizing the sentences and removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(raw_text, remove_stopwords=True, lemmetization=True, split_text=False, \\\n",
    "             ):\n",
    "    '''\n",
    "    Convert a raw review to a cleaned review\n",
    "    '''\n",
    "    #text = BeautifulSoup(raw_text, 'lxml').get_text()  #remove html\n",
    "    text = raw_text\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)  # remove non-character\n",
    "    words = letters_only.lower().split() # convert to lower case \n",
    "    \n",
    "    if remove_stopwords: # remove stopword\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "    if lemmetization==True: \n",
    "        #stemmer = SnowballStemmer('english') \n",
    "        #words = [stemmer.stem(w) for w in words]\n",
    "        # Lemmatizataion\n",
    "        \n",
    "        lmtzr = WordNetLemmatizer()\n",
    "        words = [lmtzr.lemmatize(word) for word in words]\n",
    "\n",
    "    if split_text==True:  # split text\n",
    "        return (words)\n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text data in training set and validation set\n",
    "X_train_cleaned = []\n",
    "X_test_cleaned = []\n",
    "\n",
    "for d in X_train:\n",
    "    X_train_cleaned.append(cleanText(d))\n",
    "print('Show a cleaned review in the training set : \\n',  X_train_cleaned[10])\n",
    "    \n",
    "for d in X_test:\n",
    "    X_test_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2: Using a count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data to a document-term matrix using CountVectorizer\n",
    "\n",
    "#countvector - tokenizes the text - builds vocabulary - then can make new documents using that vocabulary\n",
    "countVect = CountVectorizer() \n",
    "X_train_countVect = countVect.fit_transform(X_train_cleaned)\n",
    "\n",
    "print(\"Number of features : %d \\n\" %len(countVect.get_feature_names())) #6378 \n",
    "print(\"Show some feature names : \\n\", countVect.get_feature_names()[::1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MultinomialNB classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_countVect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelEvaluation(predictions):\n",
    "    '''\n",
    "    Print model evaluation to predicted result \n",
    "    '''\n",
    "    print (\"\\nAccuracy on test set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    #print(\"\\nAUC score : {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2A) F1 SCORE FOR Countvectorizer + Naive Bayes on extracted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validaton set\n",
    "predictions = mnb.predict(countVect.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2B) F1 SCORE FOR Countvectorizer + Logistic Regression on extracted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train_countVect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the validaton set\n",
    "predictions = lr.predict(countVect.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 3: Using TF-IDF for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data to a document-term matrix using TfidfVectorizer \n",
    "tfidf = TfidfVectorizer(min_df=5) #minimum document frequency of 5\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_cleaned)\n",
    "print(\"Number of features : %d \\n\" %len(tfidf.get_feature_names())) #1722\n",
    "print(\"Show some feature names : \\n\", tfidf.get_feature_names()[::1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MultinomialNB classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the top 10 features with smallest and the largest coefficients\n",
    "feature_names = np.array(tfidf.get_feature_names())\n",
    "sorted_coef_index = lr.coef_[0].argsort()\n",
    "print('\\nTop 10 features with smallest coefficients :\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Top 10 features with largest coefficients : \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3a) F1 SCORE FOR TF-IDF + Logistic Regression on extracted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the LR validaton set\n",
    "predictions = lr.predict(tfidf.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)\n",
    "\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3b) F1 SCORE FOR TF-IDF + Naive Bayes on extracted sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the MNB model on validaton set \n",
    "predictions = mnb.predict(tfidf.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)\n",
    "\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 4: Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split review text into parsed sentences uisng NLTK's punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def parseSent(review, tokenizer, remove_stopwords=False):\n",
    "    '''\n",
    "    Parse text into sentences\n",
    "    '''\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(cleanText(raw_sentence, remove_stopwords, split_text=True))\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# Parse each review in the training set into sentences\n",
    "sentences = []\n",
    "for review in X_train_cleaned:\n",
    "    sentences += parseSent(review, tokenizer)\n",
    "    \n",
    "print('%d parsed sentence in the training set\\n'  %len(sentences))\n",
    "print('Show a parsed sentence in the training set : \\n',  sentences[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit parsed sentences to Word2Vec model \n",
    "\n",
    "num_features = 300  #embedding dimension                     \n",
    "min_word_count = 5                \n",
    "num_workers = 4       \n",
    "context = 10                                                                                          \n",
    "downsampling = 1e-3 \n",
    "\n",
    "print(\"Training Word2Vec model ...\\n\")\n",
    "w2v = Word2Vec(sentences, workers=num_workers, size=num_features, min_count = min_word_count,\\\n",
    "                 window = context, sample = downsampling)\n",
    "w2v.init_sims(replace=True)\n",
    "w2v.save(\"w2v_300features_10minwordcounts_10context\") #save trained word2vec model\n",
    "\n",
    "print(\"Number of words in the vocabulary list : %d \\n\" %len(w2v.wv.index2word)) #4016 \n",
    "print(\"Show first 10 words in the vocalbulary list: \\n\", w2v.wv.index2word[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfrom the training data into feature vectors\n",
    "\n",
    "def makeFeatureVec(review, model, num_features):\n",
    "    '''\n",
    "    Transform a review to a feature vector by averaging feature vectors of words \n",
    "    appeared in that review and in the volcabulary list created\n",
    "    '''\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word) #index2word is the volcabulary list of the Word2Vec model\n",
    "    isZeroVec = True\n",
    "    for word in review:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec, model[word])\n",
    "            isZeroVec = False\n",
    "    if isZeroVec == False:\n",
    "        featureVec = np.divide(featureVec, nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    '''\n",
    "    Transform all reviews to feature vectors using makeFeatureVec()\n",
    "    '''\n",
    "    counter = 0\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    for review in reviews:\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model,num_features)\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature vectors for training set\n",
    "X_train_cleaned = []\n",
    "for review in X_train:\n",
    "    X_train_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
    "trainVector = getAvgFeatureVecs(X_train_cleaned, w2v, num_features)\n",
    "print(\"Training set : %d feature vectors with %d dimensions\" %trainVector.shape)\n",
    "\n",
    "\n",
    "# Get feature vectors for validation set\n",
    "X_test_cleaned = []\n",
    "for review in X_test:\n",
    "    X_test_cleaned.append(cleanText(review, remove_stopwords=True, split_text=True))\n",
    "testVector = getAvgFeatureVecs(X_test_cleaned, w2v, num_features)\n",
    "print(\"Validation set : %d feature vectors with %d dimensions\" %testVector.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4a) F1-Score for Word2Vec+LogisticRegression on extracted smoking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "lr.fit(trainVector, y_train)\n",
    "# Evaluate on the validaton set\n",
    "predictions = lr.predict(testVector)\n",
    "modelEvaluation(predictions)\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4b) F1-Score for Word2Vec+ RandomForest on extracted smoking sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(trainVector, y_train)\n",
    "predictions = rf.predict(testVector)\n",
    "modelEvaluation(predictions)\n",
    "target_names = ['Non-Smoker', 'Not Defined', 'PastSmoker', 'Smoker']\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
